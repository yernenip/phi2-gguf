{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/zTG8kwBZiuuZZpYa7t05",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "10629186b8c147c78b24a267ce68ed90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_af7f0aeb7b5c4f508fbabb651fa1c800",
              "IPY_MODEL_ac1bc18f7db84d47b6f620b851b32cb4",
              "IPY_MODEL_a01876ef3f9c4b93b9da7350154dcc7e"
            ],
            "layout": "IPY_MODEL_bb69410e49284c69bf99be6445d07b79"
          }
        },
        "af7f0aeb7b5c4f508fbabb651fa1c800": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3e3ba3339094e17be9192d6d9767c4a",
            "placeholder": "​",
            "style": "IPY_MODEL_a55ef8c610bf48cd89f27108cea7c6d9",
            "value": "Fetching 13 files: 100%"
          }
        },
        "ac1bc18f7db84d47b6f620b851b32cb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_295c8e34d1314205b72338c72296f8ba",
            "max": 13,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_10a30e1c130b40ad9bf1197dd09bfe7b",
            "value": 13
          }
        },
        "a01876ef3f9c4b93b9da7350154dcc7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f555f8388df947a5b008d1303c8d7855",
            "placeholder": "​",
            "style": "IPY_MODEL_b0131a8a5cef48558a30594e075f5312",
            "value": " 13/13 [00:39&lt;00:00,  6.22s/it]"
          }
        },
        "bb69410e49284c69bf99be6445d07b79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3e3ba3339094e17be9192d6d9767c4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a55ef8c610bf48cd89f27108cea7c6d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "295c8e34d1314205b72338c72296f8ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10a30e1c130b40ad9bf1197dd09bfe7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f555f8388df947a5b008d1303c8d7855": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0131a8a5cef48558a30594e075f5312": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d526e3b65994ba49fbb5f34780ffd90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a40bf15b62ca4695ab603ad55557199f",
              "IPY_MODEL_228afc56afeb4324bc20ef9d2afa57f9",
              "IPY_MODEL_d994c2a15d35415cbbb82eaf9d6dbfd4"
            ],
            "layout": "IPY_MODEL_0257b028b0cd418585d8e3edd91d80dd"
          }
        },
        "a40bf15b62ca4695ab603ad55557199f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d60de7baecac4e3782a3bf0fddbccf61",
            "placeholder": "​",
            "style": "IPY_MODEL_2d279e17916043d899e5ac4fa5ddba55",
            "value": "merges.txt: 100%"
          }
        },
        "228afc56afeb4324bc20ef9d2afa57f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b607534b686c4adbad287f50413439bd",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1fab5ca46ee04768831977bd53a225f4",
            "value": 456318
          }
        },
        "d994c2a15d35415cbbb82eaf9d6dbfd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ecb2715ca794f27a2ad442081768179",
            "placeholder": "​",
            "style": "IPY_MODEL_f9a619a292f84556a5f56ff1b3a93878",
            "value": " 456k/456k [00:00&lt;00:00, 1.86MB/s]"
          }
        },
        "0257b028b0cd418585d8e3edd91d80dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d60de7baecac4e3782a3bf0fddbccf61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d279e17916043d899e5ac4fa5ddba55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b607534b686c4adbad287f50413439bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fab5ca46ee04768831977bd53a225f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2ecb2715ca794f27a2ad442081768179": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9a619a292f84556a5f56ff1b3a93878": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ab7b95aa3094b1e9a3e5dffd5335d2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ccbad40d884f4f8faf01e93798ff67e6",
              "IPY_MODEL_0e84b3daf2344fa49a55a3189b823604",
              "IPY_MODEL_9ea660a5ad5a4eb9927d9e1706d56966"
            ],
            "layout": "IPY_MODEL_b2ba9f81076b40ffbfbd51484b56002e"
          }
        },
        "ccbad40d884f4f8faf01e93798ff67e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a85b569413b40f1bffd23a126c4174f",
            "placeholder": "​",
            "style": "IPY_MODEL_133ba234815b438a9b709dbd06b58a60",
            "value": "generation_config.json: 100%"
          }
        },
        "0e84b3daf2344fa49a55a3189b823604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_160571e4c26449f1996e8e829f7a8267",
            "max": 119,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94ab26118e6343d99ff46be144181149",
            "value": 119
          }
        },
        "9ea660a5ad5a4eb9927d9e1706d56966": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71aa3ee4f7b14c1a8f34189b046a33bf",
            "placeholder": "​",
            "style": "IPY_MODEL_6c24302f85144288a2a59a79f55585b9",
            "value": " 119/119 [00:00&lt;00:00, 2.80kB/s]"
          }
        },
        "b2ba9f81076b40ffbfbd51484b56002e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a85b569413b40f1bffd23a126c4174f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "133ba234815b438a9b709dbd06b58a60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "160571e4c26449f1996e8e829f7a8267": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94ab26118e6343d99ff46be144181149": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71aa3ee4f7b14c1a8f34189b046a33bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c24302f85144288a2a59a79f55585b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "539e7a3da7194aa6ad281f1fb512be18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_164af11baf26430cb8885ac70f003bc6",
              "IPY_MODEL_ea4d5c6306be4348abefbcec5050beed",
              "IPY_MODEL_6df5d371e9024a8ea3d8f86b3ab73f3e"
            ],
            "layout": "IPY_MODEL_f38feecbe53848a4958695489615c718"
          }
        },
        "164af11baf26430cb8885ac70f003bc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_837bd3980e7e4d42a3940640a0c1eae9",
            "placeholder": "​",
            "style": "IPY_MODEL_b4ecc0bd77a5454ea7922bf44645f623",
            "value": ".gitattributes: 100%"
          }
        },
        "ea4d5c6306be4348abefbcec5050beed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccb73bce1b6c4ccdaa47351ef625831a",
            "max": 1519,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_14f6dcc2bf764380b4642765854342f0",
            "value": 1519
          }
        },
        "6df5d371e9024a8ea3d8f86b3ab73f3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0059c8b74aa143b48ac3bf01c4242096",
            "placeholder": "​",
            "style": "IPY_MODEL_defb5c7d3a1d44acb393a0a47f71e0a6",
            "value": " 1.52k/1.52k [00:00&lt;00:00, 51.0kB/s]"
          }
        },
        "f38feecbe53848a4958695489615c718": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "837bd3980e7e4d42a3940640a0c1eae9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4ecc0bd77a5454ea7922bf44645f623": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ccb73bce1b6c4ccdaa47351ef625831a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14f6dcc2bf764380b4642765854342f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0059c8b74aa143b48ac3bf01c4242096": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "defb5c7d3a1d44acb393a0a47f71e0a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bb010be032a4f279ff8d6f7b3ea5974": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_84d994abea6a4ef8a5aa1d9f3c82100a",
              "IPY_MODEL_561e13dd921e4dfbac8197afe31a3b9b",
              "IPY_MODEL_1c22e41e4760420da095b57a66fc86e7"
            ],
            "layout": "IPY_MODEL_7149ccfebe504b0aafc89ba6233386f6"
          }
        },
        "84d994abea6a4ef8a5aa1d9f3c82100a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6455a678ea3941caaa56d1518f977d84",
            "placeholder": "​",
            "style": "IPY_MODEL_1482991d53d540c59a97476832205f7f",
            "value": "config.json: 100%"
          }
        },
        "561e13dd921e4dfbac8197afe31a3b9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b77177f406d54381986706f5c24d520e",
            "max": 897,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fdf9ba02647742c2bbb00b34591a0d0a",
            "value": 897
          }
        },
        "1c22e41e4760420da095b57a66fc86e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe2fb310fafa40a487a92df2a36ed53e",
            "placeholder": "​",
            "style": "IPY_MODEL_804aa40e3142437a862d454d47b8369d",
            "value": " 897/897 [00:00&lt;00:00, 57.4kB/s]"
          }
        },
        "7149ccfebe504b0aafc89ba6233386f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6455a678ea3941caaa56d1518f977d84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1482991d53d540c59a97476832205f7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b77177f406d54381986706f5c24d520e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdf9ba02647742c2bbb00b34591a0d0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe2fb310fafa40a487a92df2a36ed53e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "804aa40e3142437a862d454d47b8369d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1226125c9f24382a7289f5d550f676a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_515efc1af7b245269802cece2016f872",
              "IPY_MODEL_ab2cb1e3245c4713b0e3e1b3242c16d3",
              "IPY_MODEL_241f4b920a7d4fbc961c5531ecfd7a97"
            ],
            "layout": "IPY_MODEL_75e05830d2034bfaa7fe544a9945c967"
          }
        },
        "515efc1af7b245269802cece2016f872": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a2b3f1a7866495c986b56c0dc9c966e",
            "placeholder": "​",
            "style": "IPY_MODEL_31666cd17b8e4eb78707d6c8acff2482",
            "value": "model-00002-of-00002.safetensors: 100%"
          }
        },
        "ab2cb1e3245c4713b0e3e1b3242c16d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94d7317c531a449aa12e31ec4d4d63a4",
            "max": 563832976,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f5e6c954a9054cb9ad1c542d94ddf559",
            "value": 563832976
          }
        },
        "241f4b920a7d4fbc961c5531ecfd7a97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d10f25a735b4824af16040869a13c8f",
            "placeholder": "​",
            "style": "IPY_MODEL_52f758c144af42c4b620878c8938d69f",
            "value": " 564M/564M [00:05&lt;00:00, 69.7MB/s]"
          }
        },
        "75e05830d2034bfaa7fe544a9945c967": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a2b3f1a7866495c986b56c0dc9c966e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31666cd17b8e4eb78707d6c8acff2482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94d7317c531a449aa12e31ec4d4d63a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5e6c954a9054cb9ad1c542d94ddf559": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d10f25a735b4824af16040869a13c8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52f758c144af42c4b620878c8938d69f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab2f2ee55e24475f9bc197f9c037ae5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69bf5b1cc3de406aa8e2be83063a1de6",
              "IPY_MODEL_33a7fb205cd84a4592ce22bc0b414354",
              "IPY_MODEL_31b24293036c4b1ea633cf7ac811d952"
            ],
            "layout": "IPY_MODEL_5fe16df1e023481a8b2b1c058f631676"
          }
        },
        "69bf5b1cc3de406aa8e2be83063a1de6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_645d5b3a8f594c728c7c56da71d65164",
            "placeholder": "​",
            "style": "IPY_MODEL_2ee2d261f7a442cf99b37becedf1bf59",
            "value": "model-00001-of-00002.safetensors: 100%"
          }
        },
        "33a7fb205cd84a4592ce22bc0b414354": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54f390f906534b08a91770f1ffccf1a9",
            "max": 4995584424,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_67800f6420a24431857e1d831b732b14",
            "value": 4995584424
          }
        },
        "31b24293036c4b1ea633cf7ac811d952": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a4fc793020541198e156455d267c91e",
            "placeholder": "​",
            "style": "IPY_MODEL_2e8844e0420a48b3a16be5f87462e0a5",
            "value": " 5.00G/5.00G [00:38&lt;00:00, 213MB/s]"
          }
        },
        "5fe16df1e023481a8b2b1c058f631676": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "645d5b3a8f594c728c7c56da71d65164": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ee2d261f7a442cf99b37becedf1bf59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54f390f906534b08a91770f1ffccf1a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67800f6420a24431857e1d831b732b14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a4fc793020541198e156455d267c91e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e8844e0420a48b3a16be5f87462e0a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b4c224d1eea49669af1357784740d4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72a70c896eb84d6280ecd0ffb41660c8",
              "IPY_MODEL_9907933027d541ffad138ea289b96fea",
              "IPY_MODEL_6db1ebd91c1040a89f0f62339a971d7f"
            ],
            "layout": "IPY_MODEL_723f9f6488ed48cfacde135d98c14175"
          }
        },
        "72a70c896eb84d6280ecd0ffb41660c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_504832baf1fe46a28c5304315dd44091",
            "placeholder": "​",
            "style": "IPY_MODEL_949262cd64f348c49644b59084cfdaa8",
            "value": "added_tokens.json: 100%"
          }
        },
        "9907933027d541ffad138ea289b96fea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c18f73601cab4a45b979629fbc2115ea",
            "max": 1080,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff15a80ecb514914bdf002ea2d064b72",
            "value": 1080
          }
        },
        "6db1ebd91c1040a89f0f62339a971d7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c521196fceee436b8684115fd9477373",
            "placeholder": "​",
            "style": "IPY_MODEL_0cdbdd46bb884c698d9f34b635268970",
            "value": " 1.08k/1.08k [00:00&lt;00:00, 23.1kB/s]"
          }
        },
        "723f9f6488ed48cfacde135d98c14175": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "504832baf1fe46a28c5304315dd44091": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "949262cd64f348c49644b59084cfdaa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c18f73601cab4a45b979629fbc2115ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff15a80ecb514914bdf002ea2d064b72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c521196fceee436b8684115fd9477373": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cdbdd46bb884c698d9f34b635268970": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1c8eacb8ecc4c728e721d9344cf5809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4f51dfdb10c49908285a9a2e73b7a34",
              "IPY_MODEL_e1af870b924d4fd88dce21ac482f1904",
              "IPY_MODEL_92aac51d96484f489a53a9011d6b42db"
            ],
            "layout": "IPY_MODEL_ad55352eb6c7404c981ffadbc487af16"
          }
        },
        "f4f51dfdb10c49908285a9a2e73b7a34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8425d30c7acb4a29b6dfe90587047ae4",
            "placeholder": "​",
            "style": "IPY_MODEL_e94bb08d15814412a39a5d52c5de85ae",
            "value": "tokenizer.json: 100%"
          }
        },
        "e1af870b924d4fd88dce21ac482f1904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e3ed1485dd84f559bb2c8c7a247889f",
            "max": 2114924,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a15610bac9e7419e8768ac04cd624462",
            "value": 2114924
          }
        },
        "92aac51d96484f489a53a9011d6b42db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6827b394f13641929e6ee23674e48661",
            "placeholder": "​",
            "style": "IPY_MODEL_5ff913da749b42bb9b7e3aa4d6fa5da9",
            "value": " 2.11M/2.11M [00:00&lt;00:00, 4.21MB/s]"
          }
        },
        "ad55352eb6c7404c981ffadbc487af16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8425d30c7acb4a29b6dfe90587047ae4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e94bb08d15814412a39a5d52c5de85ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e3ed1485dd84f559bb2c8c7a247889f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a15610bac9e7419e8768ac04cd624462": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6827b394f13641929e6ee23674e48661": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ff913da749b42bb9b7e3aa4d6fa5da9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d96e7860a00a4a4d9b3777db453b384e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5de76571ee674b1bb1066cd07e4c1c00",
              "IPY_MODEL_38a74bf425ab48ed8ea876d3e0290893",
              "IPY_MODEL_f7ac6b9969cd43388f23659f6c9a3d44"
            ],
            "layout": "IPY_MODEL_17193fbecac7411c8820d205791858ce"
          }
        },
        "5de76571ee674b1bb1066cd07e4c1c00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7316f9e991974dd7bd57cf79020eb692",
            "placeholder": "​",
            "style": "IPY_MODEL_b0a9c6b49ded464e9fb5332fd2863918",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "38a74bf425ab48ed8ea876d3e0290893": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_726645c830aa46eab49f2f93d04855eb",
            "max": 441,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_96ac39a2ecc949108db77ed56de5c4a8",
            "value": 441
          }
        },
        "f7ac6b9969cd43388f23659f6c9a3d44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_772d0a3847bf45bf9686233652d79251",
            "placeholder": "​",
            "style": "IPY_MODEL_93855ebd4aaa4bdf95341559db235baf",
            "value": " 441/441 [00:00&lt;00:00, 6.98kB/s]"
          }
        },
        "17193fbecac7411c8820d205791858ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7316f9e991974dd7bd57cf79020eb692": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0a9c6b49ded464e9fb5332fd2863918": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "726645c830aa46eab49f2f93d04855eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96ac39a2ecc949108db77ed56de5c4a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "772d0a3847bf45bf9686233652d79251": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93855ebd4aaa4bdf95341559db235baf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f23b0d2abb7f474ebe5d9adb1d19d172": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8e502e1f42814b3b8e6fe2f44276eaf3",
              "IPY_MODEL_e20a145f2b3141688b3eeb8c97b4a068",
              "IPY_MODEL_617a86481e2d45abacadcaf6ebc75198"
            ],
            "layout": "IPY_MODEL_7c9287d00a4a460684eb7e4fb17895da"
          }
        },
        "8e502e1f42814b3b8e6fe2f44276eaf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a42171b7ba774704a8d340fc581fe773",
            "placeholder": "​",
            "style": "IPY_MODEL_008570cb37b64ed78c7342377b16334e",
            "value": "README.md: 100%"
          }
        },
        "e20a145f2b3141688b3eeb8c97b4a068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1445ad91f7a84a3885db6dd2eeb74446",
            "max": 5178,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9c9862b2444c4533a0f21df55afe91b3",
            "value": 5178
          }
        },
        "617a86481e2d45abacadcaf6ebc75198": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65ce685c371843d3b377922105f59e9f",
            "placeholder": "​",
            "style": "IPY_MODEL_d1740fe588c742f7b540b6c79d7f0a95",
            "value": " 5.18k/5.18k [00:00&lt;00:00, 200kB/s]"
          }
        },
        "7c9287d00a4a460684eb7e4fb17895da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a42171b7ba774704a8d340fc581fe773": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "008570cb37b64ed78c7342377b16334e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1445ad91f7a84a3885db6dd2eeb74446": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c9862b2444c4533a0f21df55afe91b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "65ce685c371843d3b377922105f59e9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1740fe588c742f7b540b6c79d7f0a95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6aa08f0d27d4d32a74f07b2cbab4912": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51a46f5e0f754cfab98adecbe442520d",
              "IPY_MODEL_f2acd1d5b09b445281e1042765adcb14",
              "IPY_MODEL_20dfe5e48b574feaa28b2b99430f764f"
            ],
            "layout": "IPY_MODEL_f903494f36d74d8881fcc321d950ad3a"
          }
        },
        "51a46f5e0f754cfab98adecbe442520d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c68b56205f1a4949be0da685a5ed8462",
            "placeholder": "​",
            "style": "IPY_MODEL_668388df64a84ee585d7034d49a7c7bb",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "f2acd1d5b09b445281e1042765adcb14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_966ca14cc45a4d3cbbab4aa4d0097582",
            "max": 7339,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e909cb42411240d6a05e8e06bb7a321c",
            "value": 7339
          }
        },
        "20dfe5e48b574feaa28b2b99430f764f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7499158a016647f6b1fbfa48932c2317",
            "placeholder": "​",
            "style": "IPY_MODEL_e1dd9137329c4b27a2aa2008696e98fb",
            "value": " 7.34k/7.34k [00:00&lt;00:00, 86.2kB/s]"
          }
        },
        "f903494f36d74d8881fcc321d950ad3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c68b56205f1a4949be0da685a5ed8462": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "668388df64a84ee585d7034d49a7c7bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "966ca14cc45a4d3cbbab4aa4d0097582": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e909cb42411240d6a05e8e06bb7a321c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7499158a016647f6b1fbfa48932c2317": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1dd9137329c4b27a2aa2008696e98fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8bcd1c4f17e4a0b92abc9449cd8f879": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_188aa684c7f440e089dc88b0b1215cd5",
              "IPY_MODEL_edf8a10fc27d4987802061ec4dbce990",
              "IPY_MODEL_b938da1f591d45549ff2d493a8772d1b"
            ],
            "layout": "IPY_MODEL_e4136865292645e2900fa15150631db0"
          }
        },
        "188aa684c7f440e089dc88b0b1215cd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1362a8e0d1a4d5198dd79d43e6b844d",
            "placeholder": "​",
            "style": "IPY_MODEL_6905cb637e9a4bda95f4b024284c7b52",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "edf8a10fc27d4987802061ec4dbce990": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_562d6c28040b48aca5f4e250ad4b4bab",
            "max": 35716,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_99cd2e2277124444a97767d7b13d2325",
            "value": 35716
          }
        },
        "b938da1f591d45549ff2d493a8772d1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c15de48e1c24d73bb1a6878962139e0",
            "placeholder": "​",
            "style": "IPY_MODEL_1f053a33249c479681110d9bf8271daa",
            "value": " 35.7k/35.7k [00:00&lt;00:00, 549kB/s]"
          }
        },
        "e4136865292645e2900fa15150631db0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1362a8e0d1a4d5198dd79d43e6b844d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6905cb637e9a4bda95f4b024284c7b52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "562d6c28040b48aca5f4e250ad4b4bab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99cd2e2277124444a97767d7b13d2325": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c15de48e1c24d73bb1a6878962139e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f053a33249c479681110d9bf8271daa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5569e495bd44425ba5df8b0f7552ec59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f447316942754df6a110b984151e7d72",
              "IPY_MODEL_231801f222df40718232f7f97ec52ac4",
              "IPY_MODEL_a744cf04fb8d41a48c543a438f40411f"
            ],
            "layout": "IPY_MODEL_229f986bbcec4f93ac6821f5f6f27820"
          }
        },
        "f447316942754df6a110b984151e7d72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96e57847c8034876b21d2e487e9590b6",
            "placeholder": "​",
            "style": "IPY_MODEL_39023edb46a24227912ce1a665599767",
            "value": "vocab.json: 100%"
          }
        },
        "231801f222df40718232f7f97ec52ac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14ad86aafcfd4a5d9ce467f7dc8a5da2",
            "max": 798156,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_122f7752dfec4f1a929c3fe5649c26bc",
            "value": 798156
          }
        },
        "a744cf04fb8d41a48c543a438f40411f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c144d8da48db40949e21ba4a62d51f67",
            "placeholder": "​",
            "style": "IPY_MODEL_d24a802e74e041e38274c00841091907",
            "value": " 798k/798k [00:00&lt;00:00, 802kB/s]"
          }
        },
        "229f986bbcec4f93ac6821f5f6f27820": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96e57847c8034876b21d2e487e9590b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39023edb46a24227912ce1a665599767": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14ad86aafcfd4a5d9ce467f7dc8a5da2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "122f7752dfec4f1a929c3fe5649c26bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c144d8da48db40949e21ba4a62d51f67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d24a802e74e041e38274c00841091907": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "673bce3c89f441f4ac408a74b4dcb676": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a99711209b8345fa9aa966d7f08bb6a5",
              "IPY_MODEL_73a030fe03664ca1a8766d60f309cc07",
              "IPY_MODEL_c078701328074d29b57358338147734b"
            ],
            "layout": "IPY_MODEL_d6286a18c51148b0999669afb1b5ddab"
          }
        },
        "a99711209b8345fa9aa966d7f08bb6a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc6758ebd9a043f5ae9b31bf79af03b6",
            "placeholder": "​",
            "style": "IPY_MODEL_30218c5f80e44bb6b0bf4b12b928f2ab",
            "value": "phi2-v2-Q5_K_M.gguf: 100%"
          }
        },
        "73a030fe03664ca1a8766d60f309cc07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3b226e05870413b9fa09292a232a3e6",
            "max": 2003057184,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aaf26cc0852544d9a1027dc25675d977",
            "value": 2003057184
          }
        },
        "c078701328074d29b57358338147734b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f12b2aac4307439c97bc65cd8741fa04",
            "placeholder": "​",
            "style": "IPY_MODEL_f13ce0f32e8946c58ba9f12fc2e04494",
            "value": " 2.00G/2.00G [01:30&lt;00:00, 33.8MB/s]"
          }
        },
        "d6286a18c51148b0999669afb1b5ddab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc6758ebd9a043f5ae9b31bf79af03b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30218c5f80e44bb6b0bf4b12b928f2ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3b226e05870413b9fa09292a232a3e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aaf26cc0852544d9a1027dc25675d977": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f12b2aac4307439c97bc65cd8741fa04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f13ce0f32e8946c58ba9f12fc2e04494": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d9976cf8cda4291a47bd407fb5a40c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00df33f0a69445708c1a8d55ea0991a3",
              "IPY_MODEL_a9abb29ab19d4d3bb495ecd40c0b062d",
              "IPY_MODEL_6bc6f650887742bd8db4f8fc9a46b872"
            ],
            "layout": "IPY_MODEL_61fa7425c0e041fe83b2c896722006f7"
          }
        },
        "00df33f0a69445708c1a8d55ea0991a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_791b39ea4905475192d714acf11ab0ca",
            "placeholder": "​",
            "style": "IPY_MODEL_88fb4b01a1b6415ea154a0324b67aa9c",
            "value": "Fetching 2 files: 100%"
          }
        },
        "a9abb29ab19d4d3bb495ecd40c0b062d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c40456e36a94d77b3e6d801c4769b6d",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51ec619b54754d8b98661a29225caa16",
            "value": 2
          }
        },
        "6bc6f650887742bd8db4f8fc9a46b872": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8548ea840444436eb9bba428945ba8a8",
            "placeholder": "​",
            "style": "IPY_MODEL_5fad5e6adf834df48d1f04a07f8640fa",
            "value": " 2/2 [00:28&lt;00:00, 16.71s/it]"
          }
        },
        "61fa7425c0e041fe83b2c896722006f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "791b39ea4905475192d714acf11ab0ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88fb4b01a1b6415ea154a0324b67aa9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c40456e36a94d77b3e6d801c4769b6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51ec619b54754d8b98661a29225caa16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8548ea840444436eb9bba428945ba8a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fad5e6adf834df48d1f04a07f8640fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23d9ac6a25ce49dcb4ac2402d23e9aca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f392117f7e1a4976a5931fda7c44b5e2",
              "IPY_MODEL_ae7498263bdc426cabcfaac07149b499",
              "IPY_MODEL_9af82a387584471699c1ecf8de0f6bf0"
            ],
            "layout": "IPY_MODEL_5bf477cc42154b5bac268323a70ad800"
          }
        },
        "f392117f7e1a4976a5931fda7c44b5e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c59150e2bc16406186dea32750b0302c",
            "placeholder": "​",
            "style": "IPY_MODEL_687b7e049c7947a29d7109930c53829a",
            "value": ".gitattributes: 100%"
          }
        },
        "ae7498263bdc426cabcfaac07149b499": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ff16270b95b43e283d6a3ad9843d923",
            "max": 1575,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8c10868a6544d7e867458442a60213e",
            "value": 1575
          }
        },
        "9af82a387584471699c1ecf8de0f6bf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_287bd3659e5e442daddf90c32aca3c5f",
            "placeholder": "​",
            "style": "IPY_MODEL_2ba25a235ca24346b46316aff9448e2e",
            "value": " 1.57k/1.57k [00:00&lt;00:00, 63.7kB/s]"
          }
        },
        "5bf477cc42154b5bac268323a70ad800": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c59150e2bc16406186dea32750b0302c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "687b7e049c7947a29d7109930c53829a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ff16270b95b43e283d6a3ad9843d923": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8c10868a6544d7e867458442a60213e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "287bd3659e5e442daddf90c32aca3c5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ba25a235ca24346b46316aff9448e2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4504f84b82a466eb8420d4d030a6e0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_94bed744ad2a4ce4949199d926d0061d",
              "IPY_MODEL_938592446589411c86d50e1b3c7f4605",
              "IPY_MODEL_b43ab566caf34bf8affbb6bf991e3162"
            ],
            "layout": "IPY_MODEL_a61bb0b00eeb4fc2a364194f3c7449e6"
          }
        },
        "94bed744ad2a4ce4949199d926d0061d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bc8a781a0d947cbab68c9e84863e99a",
            "placeholder": "​",
            "style": "IPY_MODEL_2a5a0e1172b144418919e6b03bdbb405",
            "value": "phi2-v2-Q5_K_M.gguf: 100%"
          }
        },
        "938592446589411c86d50e1b3c7f4605": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a673ed55d6c24069b54adae3c90db7ff",
            "max": 2003057184,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fbff580fc03c41849c33a244e111c405",
            "value": 2003057184
          }
        },
        "b43ab566caf34bf8affbb6bf991e3162": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcdd1879078942aa94a7428fe3e24109",
            "placeholder": "​",
            "style": "IPY_MODEL_2e7a04dc3a5441faae34f7a52971190e",
            "value": " 2.00G/2.00G [00:27&lt;00:00, 56.5MB/s]"
          }
        },
        "a61bb0b00eeb4fc2a364194f3c7449e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bc8a781a0d947cbab68c9e84863e99a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a5a0e1172b144418919e6b03bdbb405": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a673ed55d6c24069b54adae3c90db7ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbff580fc03c41849c33a244e111c405": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bcdd1879078942aa94a7428fe3e24109": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e7a04dc3a5441faae34f7a52971190e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yernenip/phi2-gguf/blob/main/Phi2_GGUF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and Merging Phi-2 with fine-tuned LoRA adapters"
      ],
      "metadata": {
        "id": "8Zjxvt5M8DI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install peft\n",
        "!pip install --upgrade torch transformers\n"
      ],
      "metadata": {
        "id": "HCX-u_1170t5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model_name = \"microsoft/phi-2\"\n",
        "torch.set_default_device(\"cuda\")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
        "                                             torch_dtype=torch.float16,\n",
        "                                             trust_remote_code=True)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "pFXA9qI970Wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import PeftModel, PeftConfig\n",
        "\n",
        "#Load the model weights from hub\n",
        "model_adapters = \"praveeny/phi2-webglm-qlora\"\n",
        "model = PeftModel.from_pretrained(model, model_adapters)\n",
        "\n",
        "model = model.merge_and_unload()\n",
        "model.save_pretrained(\"updated_adapters\")\n"
      ],
      "metadata": {
        "id": "xEu3zt-t8MSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.push_to_hub(\"phi2-webglm-guava\", private=True,\n",
        "                  commit_message=\"merged model\")\n",
        "\n",
        "tokenizer.push_to_hub(\"phi2-webglm-guava\", private=True,\n",
        "                  commit_message=\"tokenizer\")"
      ],
      "metadata": {
        "id": "_ssqNx-BAx1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up Llama.cpp and saving model in GGUF format\n",
        "\n",
        "**Note:** At this point, I would recommend disconnecting and deleting runtime. Merging the model and pushing to hub (as shown above) takes up a lot of resources.\n",
        "\n",
        "Thats why, I am installing the packages required again below."
      ],
      "metadata": {
        "id": "pA9ybK8a726a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "model_id=\"praveeny/phi2-webglm-guava\"\n",
        "#Download the repository to local_dir\n",
        "snapshot_download(repo_id=model_id, local_dir=\"phi2\",\n",
        "                  local_dir_use_symlinks=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "-ToQCFbv6Mg5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484,
          "referenced_widgets": [
            "10629186b8c147c78b24a267ce68ed90",
            "af7f0aeb7b5c4f508fbabb651fa1c800",
            "ac1bc18f7db84d47b6f620b851b32cb4",
            "a01876ef3f9c4b93b9da7350154dcc7e",
            "bb69410e49284c69bf99be6445d07b79",
            "c3e3ba3339094e17be9192d6d9767c4a",
            "a55ef8c610bf48cd89f27108cea7c6d9",
            "295c8e34d1314205b72338c72296f8ba",
            "10a30e1c130b40ad9bf1197dd09bfe7b",
            "f555f8388df947a5b008d1303c8d7855",
            "b0131a8a5cef48558a30594e075f5312",
            "3d526e3b65994ba49fbb5f34780ffd90",
            "a40bf15b62ca4695ab603ad55557199f",
            "228afc56afeb4324bc20ef9d2afa57f9",
            "d994c2a15d35415cbbb82eaf9d6dbfd4",
            "0257b028b0cd418585d8e3edd91d80dd",
            "d60de7baecac4e3782a3bf0fddbccf61",
            "2d279e17916043d899e5ac4fa5ddba55",
            "b607534b686c4adbad287f50413439bd",
            "1fab5ca46ee04768831977bd53a225f4",
            "2ecb2715ca794f27a2ad442081768179",
            "f9a619a292f84556a5f56ff1b3a93878",
            "1ab7b95aa3094b1e9a3e5dffd5335d2e",
            "ccbad40d884f4f8faf01e93798ff67e6",
            "0e84b3daf2344fa49a55a3189b823604",
            "9ea660a5ad5a4eb9927d9e1706d56966",
            "b2ba9f81076b40ffbfbd51484b56002e",
            "5a85b569413b40f1bffd23a126c4174f",
            "133ba234815b438a9b709dbd06b58a60",
            "160571e4c26449f1996e8e829f7a8267",
            "94ab26118e6343d99ff46be144181149",
            "71aa3ee4f7b14c1a8f34189b046a33bf",
            "6c24302f85144288a2a59a79f55585b9",
            "539e7a3da7194aa6ad281f1fb512be18",
            "164af11baf26430cb8885ac70f003bc6",
            "ea4d5c6306be4348abefbcec5050beed",
            "6df5d371e9024a8ea3d8f86b3ab73f3e",
            "f38feecbe53848a4958695489615c718",
            "837bd3980e7e4d42a3940640a0c1eae9",
            "b4ecc0bd77a5454ea7922bf44645f623",
            "ccb73bce1b6c4ccdaa47351ef625831a",
            "14f6dcc2bf764380b4642765854342f0",
            "0059c8b74aa143b48ac3bf01c4242096",
            "defb5c7d3a1d44acb393a0a47f71e0a6",
            "7bb010be032a4f279ff8d6f7b3ea5974",
            "84d994abea6a4ef8a5aa1d9f3c82100a",
            "561e13dd921e4dfbac8197afe31a3b9b",
            "1c22e41e4760420da095b57a66fc86e7",
            "7149ccfebe504b0aafc89ba6233386f6",
            "6455a678ea3941caaa56d1518f977d84",
            "1482991d53d540c59a97476832205f7f",
            "b77177f406d54381986706f5c24d520e",
            "fdf9ba02647742c2bbb00b34591a0d0a",
            "fe2fb310fafa40a487a92df2a36ed53e",
            "804aa40e3142437a862d454d47b8369d",
            "d1226125c9f24382a7289f5d550f676a",
            "515efc1af7b245269802cece2016f872",
            "ab2cb1e3245c4713b0e3e1b3242c16d3",
            "241f4b920a7d4fbc961c5531ecfd7a97",
            "75e05830d2034bfaa7fe544a9945c967",
            "3a2b3f1a7866495c986b56c0dc9c966e",
            "31666cd17b8e4eb78707d6c8acff2482",
            "94d7317c531a449aa12e31ec4d4d63a4",
            "f5e6c954a9054cb9ad1c542d94ddf559",
            "2d10f25a735b4824af16040869a13c8f",
            "52f758c144af42c4b620878c8938d69f",
            "ab2f2ee55e24475f9bc197f9c037ae5b",
            "69bf5b1cc3de406aa8e2be83063a1de6",
            "33a7fb205cd84a4592ce22bc0b414354",
            "31b24293036c4b1ea633cf7ac811d952",
            "5fe16df1e023481a8b2b1c058f631676",
            "645d5b3a8f594c728c7c56da71d65164",
            "2ee2d261f7a442cf99b37becedf1bf59",
            "54f390f906534b08a91770f1ffccf1a9",
            "67800f6420a24431857e1d831b732b14",
            "0a4fc793020541198e156455d267c91e",
            "2e8844e0420a48b3a16be5f87462e0a5",
            "7b4c224d1eea49669af1357784740d4b",
            "72a70c896eb84d6280ecd0ffb41660c8",
            "9907933027d541ffad138ea289b96fea",
            "6db1ebd91c1040a89f0f62339a971d7f",
            "723f9f6488ed48cfacde135d98c14175",
            "504832baf1fe46a28c5304315dd44091",
            "949262cd64f348c49644b59084cfdaa8",
            "c18f73601cab4a45b979629fbc2115ea",
            "ff15a80ecb514914bdf002ea2d064b72",
            "c521196fceee436b8684115fd9477373",
            "0cdbdd46bb884c698d9f34b635268970",
            "c1c8eacb8ecc4c728e721d9344cf5809",
            "f4f51dfdb10c49908285a9a2e73b7a34",
            "e1af870b924d4fd88dce21ac482f1904",
            "92aac51d96484f489a53a9011d6b42db",
            "ad55352eb6c7404c981ffadbc487af16",
            "8425d30c7acb4a29b6dfe90587047ae4",
            "e94bb08d15814412a39a5d52c5de85ae",
            "1e3ed1485dd84f559bb2c8c7a247889f",
            "a15610bac9e7419e8768ac04cd624462",
            "6827b394f13641929e6ee23674e48661",
            "5ff913da749b42bb9b7e3aa4d6fa5da9",
            "d96e7860a00a4a4d9b3777db453b384e",
            "5de76571ee674b1bb1066cd07e4c1c00",
            "38a74bf425ab48ed8ea876d3e0290893",
            "f7ac6b9969cd43388f23659f6c9a3d44",
            "17193fbecac7411c8820d205791858ce",
            "7316f9e991974dd7bd57cf79020eb692",
            "b0a9c6b49ded464e9fb5332fd2863918",
            "726645c830aa46eab49f2f93d04855eb",
            "96ac39a2ecc949108db77ed56de5c4a8",
            "772d0a3847bf45bf9686233652d79251",
            "93855ebd4aaa4bdf95341559db235baf",
            "f23b0d2abb7f474ebe5d9adb1d19d172",
            "8e502e1f42814b3b8e6fe2f44276eaf3",
            "e20a145f2b3141688b3eeb8c97b4a068",
            "617a86481e2d45abacadcaf6ebc75198",
            "7c9287d00a4a460684eb7e4fb17895da",
            "a42171b7ba774704a8d340fc581fe773",
            "008570cb37b64ed78c7342377b16334e",
            "1445ad91f7a84a3885db6dd2eeb74446",
            "9c9862b2444c4533a0f21df55afe91b3",
            "65ce685c371843d3b377922105f59e9f",
            "d1740fe588c742f7b540b6c79d7f0a95",
            "e6aa08f0d27d4d32a74f07b2cbab4912",
            "51a46f5e0f754cfab98adecbe442520d",
            "f2acd1d5b09b445281e1042765adcb14",
            "20dfe5e48b574feaa28b2b99430f764f",
            "f903494f36d74d8881fcc321d950ad3a",
            "c68b56205f1a4949be0da685a5ed8462",
            "668388df64a84ee585d7034d49a7c7bb",
            "966ca14cc45a4d3cbbab4aa4d0097582",
            "e909cb42411240d6a05e8e06bb7a321c",
            "7499158a016647f6b1fbfa48932c2317",
            "e1dd9137329c4b27a2aa2008696e98fb",
            "b8bcd1c4f17e4a0b92abc9449cd8f879",
            "188aa684c7f440e089dc88b0b1215cd5",
            "edf8a10fc27d4987802061ec4dbce990",
            "b938da1f591d45549ff2d493a8772d1b",
            "e4136865292645e2900fa15150631db0",
            "e1362a8e0d1a4d5198dd79d43e6b844d",
            "6905cb637e9a4bda95f4b024284c7b52",
            "562d6c28040b48aca5f4e250ad4b4bab",
            "99cd2e2277124444a97767d7b13d2325",
            "2c15de48e1c24d73bb1a6878962139e0",
            "1f053a33249c479681110d9bf8271daa",
            "5569e495bd44425ba5df8b0f7552ec59",
            "f447316942754df6a110b984151e7d72",
            "231801f222df40718232f7f97ec52ac4",
            "a744cf04fb8d41a48c543a438f40411f",
            "229f986bbcec4f93ac6821f5f6f27820",
            "96e57847c8034876b21d2e487e9590b6",
            "39023edb46a24227912ce1a665599767",
            "14ad86aafcfd4a5d9ce467f7dc8a5da2",
            "122f7752dfec4f1a929c3fe5649c26bc",
            "c144d8da48db40949e21ba4a62d51f67",
            "d24a802e74e041e38274c00841091907"
          ]
        },
        "outputId": "34df2473-32fa-475d-ac11-4391654aacf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10629186b8c147c78b24a267ce68ed90"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d526e3b65994ba49fbb5f34780ffd90"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ab7b95aa3094b1e9a3e5dffd5335d2e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              ".gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "539e7a3da7194aa6ad281f1fb512be18"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/897 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7bb010be032a4f279ff8d6f7b3ea5974"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/564M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d1226125c9f24382a7289f5d550f676a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab2f2ee55e24475f9bc197f9c037ae5b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b4c224d1eea49669af1357784740d4b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1c8eacb8ecc4c728e721d9344cf5809"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/441 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d96e7860a00a4a4d9b3777db453b384e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/5.18k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f23b0d2abb7f474ebe5d9adb1d19d172"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/7.34k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6aa08f0d27d4d32a74f07b2cbab4912"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/35.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8bcd1c4f17e4a0b92abc9449cd8f879"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5569e495bd44425ba5df8b0f7552ec59"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/phi2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup Llama.cpp and install required packages\n",
        "!git clone https://github.com/ggerganov/llama.cpp\n",
        "!cd llama.cpp && LLAMA_CUBLAS=1 make\n",
        "!pip install -r llama.cpp/requirements.txt"
      ],
      "metadata": {
        "id": "OEtAE4oLf9oK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cd89ac10-d5e8-48f4-9b59-53e62146d38b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'llama.cpp'...\n",
            "remote: Enumerating objects: 19344, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 19344 (delta 0), reused 1 (delta 0), pack-reused 19341\u001b[K\n",
            "Receiving objects: 100% (19344/19344), 22.71 MiB | 14.41 MiB/s, done.\n",
            "Resolving deltas: 100% (13524/13524), done.\n",
            "I ccache not found. Consider installing it for faster compilation.\n",
            "I llama.cpp build info: \n",
            "I UNAME_S:   Linux\n",
            "I UNAME_P:   x86_64\n",
            "I UNAME_M:   x86_64\n",
            "I CFLAGS:    -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c11   -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -Wdouble-promotion \n",
            "I CXXFLAGS:  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include \n",
            "I NVCCFLAGS: -std=c++11 -O3 -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 \n",
            "I LDFLAGS:   -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "I CC:        cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "I CXX:       g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "I NVCC:      Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "\n",
            "cc  -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c11   -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -Wdouble-promotion    -c ggml.c -o ggml.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c llama.cpp -o llama.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c common/common.cpp -o common.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c common/sampling.cpp -o sampling.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c common/grammar-parser.cpp -o grammar-parser.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c common/build-info.cpp -o build-info.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c common/console.cpp -o console.o\n",
            "nvcc -std=c++11 -O3 -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml-cuda.cu -o ggml-cuda.o\n",
            "cc  -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c11   -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -Wdouble-promotion    -c ggml-alloc.c -o ggml-alloc.o\n",
            "cc  -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c11   -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -Wdouble-promotion    -c ggml-backend.c -o ggml-backend.o\n",
            "cc -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c11   -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -Wdouble-promotion     -c ggml-quants.c -o ggml-quants.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c examples/main/main.cpp -o examples/main/main.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o console.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/main/main.o -o main -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "\n",
            "====  Run ./main -h for help.  ====\n",
            "\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c examples/quantize/quantize.cpp -o examples/quantize/quantize.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  build-info.o ggml.o llama.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/quantize/quantize.o -o quantize -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c examples/quantize-stats/quantize-stats.cpp -o examples/quantize-stats/quantize-stats.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  build-info.o ggml.o llama.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/quantize-stats/quantize-stats.o -o quantize-stats -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c examples/perplexity/perplexity.cpp -o examples/perplexity/perplexity.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/perplexity/perplexity.o -o perplexity -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c examples/imatrix/imatrix.cpp -o examples/imatrix/imatrix.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/imatrix/imatrix.o -o imatrix -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c examples/embedding/embedding.cpp -o examples/embedding/embedding.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/embedding/embedding.o -o embedding -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c pocs/vdot/vdot.cpp -o pocs/vdot/vdot.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  ggml.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o pocs/vdot/vdot.o -o vdot -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c pocs/vdot/q8dot.cpp -o pocs/vdot/q8dot.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  ggml.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o pocs/vdot/q8dot.o -o q8dot -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c common/train.cpp -o train.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c examples/train-text-from-scratch/train-text-from-scratch.cpp -o examples/train-text-from-scratch/train-text-from-scratch.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o train.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/train-text-from-scratch/train-text-from-scratch.o -o train-text-from-scratch -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c examples/convert-llama2c-to-ggml/convert-llama2c-to-ggml.cpp -o examples/convert-llama2c-to-ggml/convert-llama2c-to-ggml.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  ggml.o llama.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/convert-llama2c-to-ggml/convert-llama2c-to-ggml.o -o convert-llama2c-to-ggml -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c examples/simple/simple.cpp -o examples/simple/simple.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/simple/simple.o -o simple -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c examples/batched/batched.cpp -o examples/batched/batched.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/batched/batched.o -o batched -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c examples/batched-bench/batched-bench.cpp -o examples/batched-bench/batched-bench.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  build-info.o ggml.o llama.o common.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/batched-bench/batched-bench.o -o batched-bench -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c examples/save-load-state/save-load-state.cpp -o examples/save-load-state/save-load-state.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/save-load-state/save-load-state.o -o save-load-state -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c examples/server/server.cpp -o examples/server/server.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c examples/llava/clip.cpp -o examples/llava/clip.o -Wno-cast-qual\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -Iexamples/server examples/llava/llava.cpp ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/server/server.o examples/llava/clip.o -o server -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib  \n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c examples/gguf/gguf.cpp -o examples/gguf/gguf.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  ggml.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/gguf/gguf.o -o gguf -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c examples/llama-bench/llama-bench.cpp -o examples/llama-bench/llama-bench.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/llama-bench/llama-bench.o -o llama-bench -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -static -fPIC -c examples/llava/llava.cpp -o libllava.a -Wno-cast-qual\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c examples/llava/llava-cli.cpp -o examples/llava/llava-cli.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c examples/llava/clip.cpp  -o examples/llava/clip.o -Wno-cast-qual\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c examples/llava/llava.cpp -o examples/llava/llava.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/llava/llava-cli.o examples/llava/clip.o examples/llava/llava.o -o llava-cli -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c examples/baby-llama/baby-llama.cpp -o examples/baby-llama/baby-llama.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o train.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/baby-llama/baby-llama.o -o baby-llama -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c examples/beam-search/beam-search.cpp -o examples/beam-search/beam-search.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/beam-search/beam-search.o -o beam-search -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c examples/speculative/speculative.cpp -o examples/speculative/speculative.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/speculative/speculative.o -o speculative -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c examples/infill/infill.cpp -o examples/infill/infill.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o console.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/infill/infill.o -o infill -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c examples/tokenize/tokenize.cpp -o examples/tokenize/tokenize.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/tokenize/tokenize.o -o tokenize -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c examples/benchmark/benchmark-matmult.cpp -o examples/benchmark/benchmark-matmult.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  build-info.o ggml.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/benchmark/benchmark-matmult.o -o benchmark-matmult -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c examples/parallel/parallel.cpp -o examples/parallel/parallel.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/parallel/parallel.o -o parallel -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c examples/finetune/finetune.cpp -o examples/finetune/finetune.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o train.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/finetune/finetune.o -o finetune -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c examples/export-lora/export-lora.cpp -o examples/export-lora/export-lora.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  ggml.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/export-lora/export-lora.o -o export-lora -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c examples/lookahead/lookahead.cpp -o examples/lookahead/lookahead.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/lookahead/lookahead.o -o lookahead -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c examples/lookup/lookup.cpp -o examples/lookup/lookup.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/lookup/lookup.o -o lookup -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -c examples/passkey/passkey.cpp -o examples/passkey/passkey.o\n",
            "g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/passkey/passkey.o -o passkey -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/opt/cuda/lib64 -L/targets/x86_64-linux/lib -L/usr/local/cuda/targets/aarch64-linux/lib -L/usr/lib/wsl/lib \n",
            "cc -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/opt/cuda/include -I/targets/x86_64-linux/include -I/usr/local/cuda/targets/aarch64-linux/include  -std=c11   -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -Wdouble-promotion  -c tests/test-c.c -o tests/test-c.o\n",
            "Collecting numpy~=1.24.4 (from -r llama.cpp/./requirements/requirements-convert.txt (line 1))\n",
            "  Downloading numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece~=0.1.98 in /usr/local/lib/python3.10/dist-packages (from -r llama.cpp/./requirements/requirements-convert.txt (line 2)) (0.1.99)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.35.2 in /usr/local/lib/python3.10/dist-packages (from -r llama.cpp/./requirements/requirements-convert.txt (line 3)) (4.37.2)\n",
            "Collecting gguf>=0.1.0 (from -r llama.cpp/./requirements/requirements-convert.txt (line 4))\n",
            "  Downloading gguf-0.6.0-py3-none-any.whl (23 kB)\n",
            "Collecting protobuf<5.0.0,>=4.21.0 (from -r llama.cpp/./requirements/requirements-convert.txt (line 5))\n",
            "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch~=2.1.1 (from -r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Downloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (0.20.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1 (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (2.1.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5.0.0,>=4.35.2->-r llama.cpp/./requirements/requirements-convert.txt (line 3)) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch~=2.1.1->-r llama.cpp/./requirements/requirements-convert-hf-to-gguf.txt (line 2)) (1.3.0)\n",
            "Installing collected packages: protobuf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, gguf, nvidia-cusolver-cu12, torch\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu121\n",
            "    Uninstalling torch-2.1.0+cu121:\n",
            "      Successfully uninstalled torch-2.1.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.25.3 which is incompatible.\n",
            "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gguf-0.6.0 numpy-1.24.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 protobuf-4.25.3 torch-2.1.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python llama.cpp/convert-hf-to-gguf.py phi2 --outfile \"phi2/phi2-v2-fp16.bin\" --outtype f16"
      ],
      "metadata": {
        "id": "ujCJoFKybLoF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "107050fa-fac7-4b08-9334-ade51a1062a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model: phi2\n",
            "gguf: This GGUF file is for Little Endian only\n",
            "Set model parameters\n",
            "Set model tokenizer\n",
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
            "0it [00:00, ?it/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "gguf: Adding 50000 merge(s).\n",
            "gguf: Setting special token type bos to 50256\n",
            "gguf: Setting special token type eos to 50256\n",
            "gguf: Setting special token type unk to 50256\n",
            "Exporting model to 'phi2/phi2-v2-fp16.bin'\n",
            "gguf: loading model part 'model-00001-of-00002.safetensors'\n",
            "token_embd.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.0.attn_norm.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.0.attn_norm.weight, n_dims = 1, torch.float16 --> float32\n",
            "blk.0.ffn_up.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.0.ffn_up.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.0.ffn_down.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.0.ffn_down.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.0.attn_output.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.0.attn_output.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.0.attn_k.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.0.attn_k.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.0.attn_q.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.0.attn_q.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.0.attn_v.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.0.attn_v.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.1.attn_norm.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.1.attn_norm.weight, n_dims = 1, torch.float16 --> float32\n",
            "blk.1.ffn_up.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.1.ffn_up.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.1.ffn_down.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.1.ffn_down.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.1.attn_output.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.1.attn_output.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.1.attn_k.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.1.attn_k.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.1.attn_q.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.1.attn_q.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.1.attn_v.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.1.attn_v.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.10.attn_norm.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.10.attn_norm.weight, n_dims = 1, torch.float16 --> float32\n",
            "blk.10.ffn_up.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.10.ffn_up.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.10.ffn_down.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.10.ffn_down.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.10.attn_output.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.10.attn_output.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.10.attn_k.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.10.attn_k.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.10.attn_q.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.10.attn_q.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.10.attn_v.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.10.attn_v.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.11.attn_norm.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.11.attn_norm.weight, n_dims = 1, torch.float16 --> float32\n",
            "blk.11.ffn_up.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.11.ffn_up.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.11.ffn_down.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.11.ffn_down.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.11.attn_output.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.11.attn_output.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.11.attn_k.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.11.attn_k.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.11.attn_q.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.11.attn_q.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.11.attn_v.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.11.attn_v.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.12.attn_norm.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.12.attn_norm.weight, n_dims = 1, torch.float16 --> float32\n",
            "blk.12.ffn_up.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.12.ffn_up.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.12.ffn_down.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.12.ffn_down.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.12.attn_output.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.12.attn_output.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.12.attn_k.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.12.attn_k.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.12.attn_q.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.12.attn_q.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.12.attn_v.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.12.attn_v.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.13.attn_norm.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.13.attn_norm.weight, n_dims = 1, torch.float16 --> float32\n",
            "blk.13.ffn_up.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.13.ffn_up.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.13.ffn_down.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.13.ffn_down.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.13.attn_output.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.13.attn_output.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.13.attn_k.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.13.attn_k.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.13.attn_q.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.13.attn_q.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.13.attn_v.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.13.attn_v.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.14.attn_norm.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.14.attn_norm.weight, n_dims = 1, torch.float16 --> float32\n",
            "blk.14.ffn_up.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.14.ffn_up.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.14.ffn_down.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.14.ffn_down.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.14.attn_output.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.14.attn_output.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.14.attn_k.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.14.attn_k.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.14.attn_q.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.14.attn_q.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.14.attn_v.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.14.attn_v.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.15.attn_norm.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.15.attn_norm.weight, n_dims = 1, torch.float16 --> float32\n",
            "blk.15.ffn_up.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.15.ffn_up.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.15.ffn_down.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.15.ffn_down.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.15.attn_output.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.15.attn_output.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.15.attn_k.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.15.attn_k.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.15.attn_q.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.15.attn_q.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.15.attn_v.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.15.attn_v.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.16.attn_norm.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.16.attn_norm.weight, n_dims = 1, torch.float16 --> float32\n",
            "blk.16.ffn_up.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.16.ffn_up.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.16.ffn_down.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.16.ffn_down.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.16.attn_output.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.16.attn_output.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.16.attn_k.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.16.attn_k.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.16.attn_q.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.16.attn_q.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.16.attn_v.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.16.attn_v.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.17.attn_norm.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.17.attn_norm.weight, n_dims = 1, torch.float16 --> float32\n",
            "blk.17.ffn_up.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.17.ffn_up.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.17.ffn_down.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.17.ffn_down.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.17.attn_output.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.17.attn_output.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.17.attn_k.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.17.attn_k.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.17.attn_q.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.17.attn_q.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.17.attn_v.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.17.attn_v.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.18.attn_norm.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.18.attn_norm.weight, n_dims = 1, torch.float16 --> float32\n",
            "blk.18.ffn_up.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.18.ffn_up.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.18.ffn_down.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.18.ffn_down.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.18.attn_output.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.18.attn_output.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.18.attn_k.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.18.attn_k.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.18.attn_q.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.18.attn_q.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.18.attn_v.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.18.attn_v.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.19.attn_norm.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.19.attn_norm.weight, n_dims = 1, torch.float16 --> float32\n",
            "blk.19.ffn_up.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.19.ffn_up.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.19.ffn_down.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.19.ffn_down.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.19.attn_output.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.19.attn_output.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.19.attn_k.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.19.attn_k.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.19.attn_q.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.19.attn_q.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.19.attn_v.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.19.attn_v.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.2.attn_norm.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.2.attn_norm.weight, n_dims = 1, torch.float16 --> float32\n",
            "blk.2.ffn_up.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.2.ffn_up.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.2.ffn_down.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.2.ffn_down.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.2.attn_output.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.2.attn_output.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.2.attn_k.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.2.attn_k.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.2.attn_q.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.2.attn_q.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.2.attn_v.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.2.attn_v.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.20.attn_norm.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.20.attn_norm.weight, n_dims = 1, torch.float16 --> float32\n",
            "blk.20.ffn_up.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.20.ffn_up.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.20.ffn_down.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.20.ffn_down.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.20.attn_output.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.20.attn_output.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.20.attn_k.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.20.attn_k.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.20.attn_q.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.20.attn_q.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.20.attn_v.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.20.attn_v.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.21.attn_norm.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.21.attn_norm.weight, n_dims = 1, torch.float16 --> float32\n",
            "blk.21.ffn_up.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.21.ffn_up.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.21.ffn_down.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.21.ffn_down.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.21.attn_output.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.21.attn_output.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.21.attn_k.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.21.attn_k.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.21.attn_q.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.21.attn_q.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.21.attn_v.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.21.attn_v.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.22.attn_norm.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.22.attn_norm.weight, n_dims = 1, torch.float16 --> float32\n",
            "blk.22.ffn_up.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.22.ffn_up.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.22.ffn_down.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.22.ffn_down.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.22.attn_output.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.22.attn_output.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.22.attn_k.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.22.attn_k.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.22.attn_q.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.22.attn_q.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.22.attn_v.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.22.attn_v.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.23.attn_norm.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.23.attn_norm.weight, n_dims = 1, torch.float16 --> float32\n",
            "blk.23.ffn_up.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.23.ffn_up.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.23.ffn_down.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.23.ffn_down.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.23.attn_output.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.23.attn_output.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.23.attn_k.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.23.attn_k.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.23.attn_q.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.23.attn_q.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.23.attn_v.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.23.attn_v.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.24.attn_norm.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.24.attn_norm.weight, n_dims = 1, torch.float16 --> float32\n",
            "blk.24.ffn_up.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.24.ffn_up.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.24.ffn_down.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.24.ffn_down.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.24.attn_output.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.24.attn_output.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.24.attn_k.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.24.attn_k.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.24.attn_q.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.24.attn_q.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.24.attn_v.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.24.attn_v.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.25.attn_norm.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.25.attn_norm.weight, n_dims = 1, torch.float16 --> float32\n",
            "blk.25.ffn_up.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.25.ffn_up.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.25.ffn_down.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.25.ffn_down.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.25.attn_output.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.25.attn_output.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.25.attn_k.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.25.attn_k.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.25.attn_q.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.25.attn_q.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.25.attn_v.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.25.attn_v.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.26.attn_norm.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.26.attn_norm.weight, n_dims = 1, torch.float16 --> float32\n",
            "blk.26.ffn_up.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.26.ffn_up.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.26.ffn_down.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.26.ffn_down.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.26.attn_output.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.26.attn_output.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.26.attn_k.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.26.attn_k.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.26.attn_q.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.26.attn_q.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.26.attn_v.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.26.attn_v.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.27.attn_norm.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.27.attn_norm.weight, n_dims = 1, torch.float16 --> float32\n",
            "blk.27.ffn_up.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.27.ffn_up.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.27.ffn_down.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.27.ffn_down.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.27.attn_output.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.27.attn_output.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.27.attn_k.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.27.attn_k.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.27.attn_q.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.27.attn_q.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.27.attn_v.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.27.attn_v.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.28.attn_norm.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.28.attn_norm.weight, n_dims = 1, torch.float16 --> float32\n",
            "blk.28.ffn_up.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.28.ffn_up.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.28.ffn_down.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.28.ffn_down.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.28.attn_output.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.28.attn_output.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.28.attn_k.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.28.attn_k.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.28.attn_q.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.28.attn_q.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.28.attn_v.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.28.attn_v.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.29.attn_norm.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.29.attn_norm.weight, n_dims = 1, torch.float16 --> float32\n",
            "blk.29.ffn_up.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.29.ffn_up.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.29.ffn_down.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.29.ffn_down.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.29.attn_output.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.29.attn_output.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.29.attn_k.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.29.attn_k.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.29.attn_q.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.29.attn_q.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.29.attn_v.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.29.attn_v.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.3.attn_norm.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.3.attn_norm.weight, n_dims = 1, torch.float16 --> float32\n",
            "blk.3.ffn_up.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.3.ffn_up.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.3.ffn_down.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.3.ffn_down.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.3.attn_output.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.3.attn_output.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.3.attn_k.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.3.attn_k.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.3.attn_q.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.3.attn_q.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.3.attn_v.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.3.attn_v.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.30.attn_q.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.30.attn_q.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.4.attn_norm.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.4.attn_norm.weight, n_dims = 1, torch.float16 --> float32\n",
            "blk.4.ffn_up.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.4.ffn_up.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.4.ffn_down.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.4.ffn_down.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.4.attn_output.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.4.attn_output.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.4.attn_k.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.4.attn_k.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.4.attn_q.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.4.attn_q.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.4.attn_v.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.4.attn_v.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.5.attn_norm.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.5.attn_norm.weight, n_dims = 1, torch.float16 --> float32\n",
            "blk.5.ffn_up.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.5.ffn_up.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.5.ffn_down.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.5.ffn_down.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.5.attn_output.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.5.attn_output.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.5.attn_k.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.5.attn_k.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.5.attn_q.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.5.attn_q.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.5.attn_v.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.5.attn_v.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.6.attn_norm.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.6.attn_norm.weight, n_dims = 1, torch.float16 --> float32\n",
            "blk.6.ffn_up.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.6.ffn_up.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.6.ffn_down.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.6.ffn_down.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.6.attn_output.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.6.attn_output.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.6.attn_k.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.6.attn_k.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.6.attn_q.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.6.attn_q.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.6.attn_v.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.6.attn_v.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.7.attn_norm.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.7.attn_norm.weight, n_dims = 1, torch.float16 --> float32\n",
            "blk.7.ffn_up.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.7.ffn_up.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.7.ffn_down.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.7.ffn_down.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.7.attn_output.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.7.attn_output.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.7.attn_k.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.7.attn_k.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.7.attn_q.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.7.attn_q.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.7.attn_v.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.7.attn_v.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.8.attn_norm.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.8.attn_norm.weight, n_dims = 1, torch.float16 --> float32\n",
            "blk.8.ffn_up.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.8.ffn_up.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.8.ffn_down.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.8.ffn_down.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.8.attn_output.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.8.attn_output.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.8.attn_k.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.8.attn_k.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.8.attn_q.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.8.attn_q.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.8.attn_v.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.8.attn_v.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.9.attn_norm.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.9.attn_norm.weight, n_dims = 1, torch.float16 --> float32\n",
            "blk.9.ffn_up.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.9.ffn_up.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.9.ffn_down.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.9.ffn_down.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.9.attn_output.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.9.attn_output.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.9.attn_k.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.9.attn_k.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.9.attn_q.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.9.attn_q.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.9.attn_v.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.9.attn_v.weight, n_dims = 2, torch.float16 --> float16\n",
            "gguf: loading model part 'model-00002-of-00002.safetensors'\n",
            "output.bias, n_dims = 1, torch.float16 --> float32\n",
            "output.weight, n_dims = 2, torch.float16 --> float16\n",
            "output_norm.bias, n_dims = 1, torch.float16 --> float32\n",
            "output_norm.weight, n_dims = 1, torch.float16 --> float32\n",
            "blk.30.attn_norm.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.30.attn_norm.weight, n_dims = 1, torch.float16 --> float32\n",
            "blk.30.ffn_up.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.30.ffn_up.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.30.ffn_down.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.30.ffn_down.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.30.attn_output.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.30.attn_output.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.30.attn_k.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.30.attn_k.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.30.attn_v.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.30.attn_v.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.31.attn_norm.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.31.attn_norm.weight, n_dims = 1, torch.float16 --> float32\n",
            "blk.31.ffn_up.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.31.ffn_up.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.31.ffn_down.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.31.ffn_down.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.31.attn_output.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.31.attn_output.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.31.attn_k.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.31.attn_k.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.31.attn_q.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.31.attn_q.weight, n_dims = 2, torch.float16 --> float16\n",
            "blk.31.attn_v.bias, n_dims = 1, torch.float16 --> float32\n",
            "blk.31.attn_v.weight, n_dims = 2, torch.float16 --> float16\n",
            "Model successfully exported to 'phi2/phi2-v2-fp16.bin'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./llama.cpp/quantize \"phi2/phi2-v2-fp16.bin\" \"phi2/phi2-v2-Q5_K_M.gguf\" \"q5_k_m\""
      ],
      "metadata": {
        "id": "65Njd-k_FJPk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53aec09f-d6ec-46aa-91a4-a81c0f1064ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ggml_init_cublas: GGML_CUDA_FORCE_MMQ:   no\n",
            "ggml_init_cublas: CUDA_USE_TENSOR_CORES: yes\n",
            "ggml_init_cublas: found 1 CUDA devices:\n",
            "  Device 0: Tesla T4, compute capability 7.5, VMM: yes\n",
            "main: build = 2254 (9e359a4f)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: quantizing 'phi2/phi2-v2-fp16.bin' to 'phi2/phi2-v2-Q5_K_M.gguf' as Q5_K_M\n",
            "llama_model_loader: loaded meta data with 19 key-value pairs and 453 tensors from phi2/phi2-v2-fp16.bin (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = phi2\n",
            "llama_model_loader: - kv   1:                               general.name str              = Phi2\n",
            "llama_model_loader: - kv   2:                        phi2.context_length u32              = 2048\n",
            "llama_model_loader: - kv   3:                      phi2.embedding_length u32              = 2560\n",
            "llama_model_loader: - kv   4:                   phi2.feed_forward_length u32              = 10240\n",
            "llama_model_loader: - kv   5:                           phi2.block_count u32              = 32\n",
            "llama_model_loader: - kv   6:                  phi2.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   7:               phi2.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv   8:          phi2.attention.layer_norm_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv   9:                  phi2.rope.dimension_count u32              = 32\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  11:               tokenizer.ggml.add_bos_token bool             = false\n",
            "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,51200]   = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,51200]   = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  15:                      tokenizer.ggml.merges arr[str,50000]   = [\"Ġ t\", \"Ġ a\", \"h e\", \"i n\", \"r e\",...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 50256\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 50256\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 50256\n",
            "llama_model_loader: - type  f32:  259 tensors\n",
            "llama_model_loader: - type  f16:  194 tensors\n",
            "llama_model_quantize_internal ============ Strange model: n_attention_wv = 32, n_ffn_down = 64, hparams.n_layer = 32\n",
            "llama_model_quantize_internal: meta size = 1813024 bytes\n",
            "[   1/ 453]                    token_embd.weight - [ 2560, 51200,     1,     1], type =    f16, quantizing to q5_K .. size =   250.00 MiB ->    85.94 MiB\n",
            "[   2/ 453]                 blk.0.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[   3/ 453]               blk.0.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[   4/ 453]                    blk.0.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[   5/ 453]                  blk.0.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[   6/ 453]                  blk.0.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[   7/ 453]                blk.0.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, quantizing to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[   8/ 453]               blk.0.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[   9/ 453]             blk.0.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[  10/ 453]                    blk.0.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  11/ 453]                  blk.0.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[  12/ 453]                    blk.0.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  13/ 453]                  blk.0.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[  14/ 453]                    blk.0.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  15/ 453]                  blk.0.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  16/ 453]                 blk.1.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  17/ 453]               blk.1.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  18/ 453]                    blk.1.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[  19/ 453]                  blk.1.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[  20/ 453]                  blk.1.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  21/ 453]                blk.1.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, quantizing to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  22/ 453]               blk.1.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  23/ 453]             blk.1.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[  24/ 453]                    blk.1.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  25/ 453]                  blk.1.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[  26/ 453]                    blk.1.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  27/ 453]                  blk.1.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[  28/ 453]                    blk.1.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  29/ 453]                  blk.1.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  30/ 453]                blk.10.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  31/ 453]              blk.10.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  32/ 453]                   blk.10.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[  33/ 453]                 blk.10.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[  34/ 453]                 blk.10.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  35/ 453]               blk.10.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, quantizing to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  36/ 453]              blk.10.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  37/ 453]            blk.10.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[  38/ 453]                   blk.10.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  39/ 453]                 blk.10.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[  40/ 453]                   blk.10.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  41/ 453]                 blk.10.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[  42/ 453]                   blk.10.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  43/ 453]                 blk.10.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  44/ 453]                blk.11.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  45/ 453]              blk.11.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  46/ 453]                   blk.11.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[  47/ 453]                 blk.11.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[  48/ 453]                 blk.11.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  49/ 453]               blk.11.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, quantizing to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  50/ 453]              blk.11.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  51/ 453]            blk.11.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[  52/ 453]                   blk.11.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  53/ 453]                 blk.11.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[  54/ 453]                   blk.11.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  55/ 453]                 blk.11.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[  56/ 453]                   blk.11.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  57/ 453]                 blk.11.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[  58/ 453]                blk.12.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  59/ 453]              blk.12.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  60/ 453]                   blk.12.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[  61/ 453]                 blk.12.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[  62/ 453]                 blk.12.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  63/ 453]               blk.12.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, quantizing to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  64/ 453]              blk.12.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  65/ 453]            blk.12.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[  66/ 453]                   blk.12.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  67/ 453]                 blk.12.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[  68/ 453]                   blk.12.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  69/ 453]                 blk.12.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[  70/ 453]                   blk.12.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  71/ 453]                 blk.12.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[  72/ 453]                blk.13.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  73/ 453]              blk.13.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  74/ 453]                   blk.13.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[  75/ 453]                 blk.13.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[  76/ 453]                 blk.13.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  77/ 453]               blk.13.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, quantizing to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  78/ 453]              blk.13.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  79/ 453]            blk.13.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[  80/ 453]                   blk.13.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  81/ 453]                 blk.13.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[  82/ 453]                   blk.13.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  83/ 453]                 blk.13.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[  84/ 453]                   blk.13.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  85/ 453]                 blk.13.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[  86/ 453]                blk.14.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  87/ 453]              blk.14.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  88/ 453]                   blk.14.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[  89/ 453]                 blk.14.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[  90/ 453]                 blk.14.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  91/ 453]               blk.14.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, quantizing to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  92/ 453]              blk.14.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  93/ 453]            blk.14.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[  94/ 453]                   blk.14.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  95/ 453]                 blk.14.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[  96/ 453]                   blk.14.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  97/ 453]                 blk.14.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[  98/ 453]                   blk.14.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  99/ 453]                 blk.14.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 100/ 453]                blk.15.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 101/ 453]              blk.15.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 102/ 453]                   blk.15.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 103/ 453]                 blk.15.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 104/ 453]                 blk.15.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 105/ 453]               blk.15.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, quantizing to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 106/ 453]              blk.15.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 107/ 453]            blk.15.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 108/ 453]                   blk.15.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 109/ 453]                 blk.15.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 110/ 453]                   blk.15.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 111/ 453]                 blk.15.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 112/ 453]                   blk.15.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 113/ 453]                 blk.15.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 114/ 453]                blk.16.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 115/ 453]              blk.16.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 116/ 453]                   blk.16.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 117/ 453]                 blk.16.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 118/ 453]                 blk.16.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 119/ 453]               blk.16.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 120/ 453]              blk.16.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 121/ 453]            blk.16.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 122/ 453]                   blk.16.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 123/ 453]                 blk.16.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 124/ 453]                   blk.16.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 125/ 453]                 blk.16.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 126/ 453]                   blk.16.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 127/ 453]                 blk.16.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 128/ 453]                blk.17.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 129/ 453]              blk.17.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 130/ 453]                   blk.17.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 131/ 453]                 blk.17.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 132/ 453]                 blk.17.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 133/ 453]               blk.17.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 134/ 453]              blk.17.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 135/ 453]            blk.17.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 136/ 453]                   blk.17.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 137/ 453]                 blk.17.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 138/ 453]                   blk.17.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 139/ 453]                 blk.17.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 140/ 453]                   blk.17.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 141/ 453]                 blk.17.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 142/ 453]                blk.18.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 143/ 453]              blk.18.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 144/ 453]                   blk.18.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 145/ 453]                 blk.18.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 146/ 453]                 blk.18.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 147/ 453]               blk.18.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, quantizing to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 148/ 453]              blk.18.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 149/ 453]            blk.18.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 150/ 453]                   blk.18.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 151/ 453]                 blk.18.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 152/ 453]                   blk.18.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 153/ 453]                 blk.18.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 154/ 453]                   blk.18.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 155/ 453]                 blk.18.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 156/ 453]                blk.19.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 157/ 453]              blk.19.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 158/ 453]                   blk.19.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 159/ 453]                 blk.19.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 160/ 453]                 blk.19.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 161/ 453]               blk.19.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 162/ 453]              blk.19.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 163/ 453]            blk.19.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 164/ 453]                   blk.19.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 165/ 453]                 blk.19.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 166/ 453]                   blk.19.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 167/ 453]                 blk.19.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 168/ 453]                   blk.19.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 169/ 453]                 blk.19.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 170/ 453]                 blk.2.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 171/ 453]               blk.2.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 172/ 453]                    blk.2.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 173/ 453]                  blk.2.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 174/ 453]                  blk.2.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 175/ 453]                blk.2.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 176/ 453]               blk.2.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 177/ 453]             blk.2.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 178/ 453]                    blk.2.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 179/ 453]                  blk.2.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 180/ 453]                    blk.2.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 181/ 453]                  blk.2.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 182/ 453]                    blk.2.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 183/ 453]                  blk.2.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 184/ 453]                blk.20.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 185/ 453]              blk.20.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 186/ 453]                   blk.20.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 187/ 453]                 blk.20.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 188/ 453]                 blk.20.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 189/ 453]               blk.20.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, quantizing to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 190/ 453]              blk.20.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 191/ 453]            blk.20.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 192/ 453]                   blk.20.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 193/ 453]                 blk.20.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 194/ 453]                   blk.20.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 195/ 453]                 blk.20.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 196/ 453]                   blk.20.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 197/ 453]                 blk.20.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 198/ 453]                blk.21.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 199/ 453]              blk.21.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 200/ 453]                   blk.21.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 201/ 453]                 blk.21.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 202/ 453]                 blk.21.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 203/ 453]               blk.21.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 204/ 453]              blk.21.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 205/ 453]            blk.21.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 206/ 453]                   blk.21.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 207/ 453]                 blk.21.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 208/ 453]                   blk.21.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 209/ 453]                 blk.21.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 210/ 453]                   blk.21.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 211/ 453]                 blk.21.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 212/ 453]                blk.22.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 213/ 453]              blk.22.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 214/ 453]                   blk.22.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 215/ 453]                 blk.22.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 216/ 453]                 blk.22.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 217/ 453]               blk.22.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 218/ 453]              blk.22.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 219/ 453]            blk.22.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 220/ 453]                   blk.22.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 221/ 453]                 blk.22.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 222/ 453]                   blk.22.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 223/ 453]                 blk.22.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 224/ 453]                   blk.22.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 225/ 453]                 blk.22.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 226/ 453]                blk.23.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 227/ 453]              blk.23.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 228/ 453]                   blk.23.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 229/ 453]                 blk.23.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 230/ 453]                 blk.23.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 231/ 453]               blk.23.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, quantizing to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 232/ 453]              blk.23.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 233/ 453]            blk.23.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 234/ 453]                   blk.23.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 235/ 453]                 blk.23.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 236/ 453]                   blk.23.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 237/ 453]                 blk.23.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 238/ 453]                   blk.23.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 239/ 453]                 blk.23.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 240/ 453]                blk.24.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 241/ 453]              blk.24.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 242/ 453]                   blk.24.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 243/ 453]                 blk.24.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 244/ 453]                 blk.24.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 245/ 453]               blk.24.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 246/ 453]              blk.24.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 247/ 453]            blk.24.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 248/ 453]                   blk.24.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 249/ 453]                 blk.24.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 250/ 453]                   blk.24.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 251/ 453]                 blk.24.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 252/ 453]                   blk.24.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 253/ 453]                 blk.24.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 254/ 453]                blk.25.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 255/ 453]              blk.25.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 256/ 453]                   blk.25.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 257/ 453]                 blk.25.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 258/ 453]                 blk.25.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 259/ 453]               blk.25.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 260/ 453]              blk.25.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 261/ 453]            blk.25.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 262/ 453]                   blk.25.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 263/ 453]                 blk.25.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 264/ 453]                   blk.25.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 265/ 453]                 blk.25.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 266/ 453]                   blk.25.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 267/ 453]                 blk.25.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 268/ 453]                blk.26.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 269/ 453]              blk.26.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 270/ 453]                   blk.26.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 271/ 453]                 blk.26.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 272/ 453]                 blk.26.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 273/ 453]               blk.26.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, quantizing to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 274/ 453]              blk.26.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 275/ 453]            blk.26.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 276/ 453]                   blk.26.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 277/ 453]                 blk.26.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 278/ 453]                   blk.26.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 279/ 453]                 blk.26.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 280/ 453]                   blk.26.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 281/ 453]                 blk.26.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 282/ 453]                blk.27.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 283/ 453]              blk.27.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 284/ 453]                   blk.27.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 285/ 453]                 blk.27.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 286/ 453]                 blk.27.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 287/ 453]               blk.27.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 288/ 453]              blk.27.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 289/ 453]            blk.27.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 290/ 453]                   blk.27.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 291/ 453]                 blk.27.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 292/ 453]                   blk.27.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 293/ 453]                 blk.27.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 294/ 453]                   blk.27.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 295/ 453]                 blk.27.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 296/ 453]                blk.28.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 297/ 453]              blk.28.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 298/ 453]                   blk.28.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 299/ 453]                 blk.28.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 300/ 453]                 blk.28.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 301/ 453]               blk.28.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 302/ 453]              blk.28.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 303/ 453]            blk.28.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 304/ 453]                   blk.28.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 305/ 453]                 blk.28.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 306/ 453]                   blk.28.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 307/ 453]                 blk.28.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 308/ 453]                   blk.28.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 309/ 453]                 blk.28.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 310/ 453]                blk.29.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 311/ 453]              blk.29.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 312/ 453]                   blk.29.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 313/ 453]                 blk.29.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 314/ 453]                 blk.29.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 315/ 453]               blk.29.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, quantizing to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 316/ 453]              blk.29.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 317/ 453]            blk.29.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 318/ 453]                   blk.29.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 319/ 453]                 blk.29.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 320/ 453]                   blk.29.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 321/ 453]                 blk.29.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 322/ 453]                   blk.29.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 323/ 453]                 blk.29.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 324/ 453]                 blk.3.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 325/ 453]               blk.3.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 326/ 453]                    blk.3.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 327/ 453]                  blk.3.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 328/ 453]                  blk.3.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 329/ 453]                blk.3.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 330/ 453]               blk.3.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 331/ 453]             blk.3.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 332/ 453]                    blk.3.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 333/ 453]                  blk.3.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 334/ 453]                    blk.3.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 335/ 453]                  blk.3.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 336/ 453]                    blk.3.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 337/ 453]                  blk.3.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 338/ 453]                   blk.30.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 339/ 453]                 blk.30.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 340/ 453]                 blk.4.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 341/ 453]               blk.4.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 342/ 453]                    blk.4.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 343/ 453]                  blk.4.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 344/ 453]                  blk.4.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 345/ 453]                blk.4.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 346/ 453]               blk.4.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 347/ 453]             blk.4.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 348/ 453]                    blk.4.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 349/ 453]                  blk.4.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 350/ 453]                    blk.4.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 351/ 453]                  blk.4.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 352/ 453]                    blk.4.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 353/ 453]                  blk.4.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 354/ 453]                 blk.5.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 355/ 453]               blk.5.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 356/ 453]                    blk.5.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 357/ 453]                  blk.5.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 358/ 453]                  blk.5.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 359/ 453]                blk.5.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, quantizing to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 360/ 453]               blk.5.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 361/ 453]             blk.5.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 362/ 453]                    blk.5.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 363/ 453]                  blk.5.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 364/ 453]                    blk.5.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 365/ 453]                  blk.5.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 366/ 453]                    blk.5.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 367/ 453]                  blk.5.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 368/ 453]                 blk.6.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 369/ 453]               blk.6.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 370/ 453]                    blk.6.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 371/ 453]                  blk.6.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 372/ 453]                  blk.6.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 373/ 453]                blk.6.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 374/ 453]               blk.6.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 375/ 453]             blk.6.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 376/ 453]                    blk.6.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 377/ 453]                  blk.6.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 378/ 453]                    blk.6.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 379/ 453]                  blk.6.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 380/ 453]                    blk.6.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 381/ 453]                  blk.6.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 382/ 453]                 blk.7.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 383/ 453]               blk.7.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 384/ 453]                    blk.7.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 385/ 453]                  blk.7.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 386/ 453]                  blk.7.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 387/ 453]                blk.7.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 388/ 453]               blk.7.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 389/ 453]             blk.7.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 390/ 453]                    blk.7.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 391/ 453]                  blk.7.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 392/ 453]                    blk.7.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 393/ 453]                  blk.7.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 394/ 453]                    blk.7.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 395/ 453]                  blk.7.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 396/ 453]                 blk.8.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 397/ 453]               blk.8.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 398/ 453]                    blk.8.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 399/ 453]                  blk.8.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 400/ 453]                  blk.8.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 401/ 453]                blk.8.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, quantizing to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 402/ 453]               blk.8.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 403/ 453]             blk.8.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 404/ 453]                    blk.8.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 405/ 453]                  blk.8.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 406/ 453]                    blk.8.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 407/ 453]                  blk.8.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 408/ 453]                    blk.8.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 409/ 453]                  blk.8.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 410/ 453]                 blk.9.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 411/ 453]               blk.9.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 412/ 453]                    blk.9.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 413/ 453]                  blk.9.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 414/ 453]                  blk.9.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 415/ 453]                blk.9.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 416/ 453]               blk.9.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 417/ 453]             blk.9.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 418/ 453]                    blk.9.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 419/ 453]                  blk.9.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 420/ 453]                    blk.9.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 421/ 453]                  blk.9.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 422/ 453]                    blk.9.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 423/ 453]                  blk.9.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 424/ 453]                          output.bias - [51200,     1,     1,     1], type =    f32, size =    0.195 MB\n",
            "[ 425/ 453]                        output.weight - [ 2560, 51200,     1,     1], type =    f16, quantizing to q6_K .. size =   250.00 MiB ->   102.54 MiB\n",
            "[ 426/ 453]                     output_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 427/ 453]                   output_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 428/ 453]                blk.30.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 429/ 453]              blk.30.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 430/ 453]                   blk.30.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 431/ 453]                 blk.30.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 432/ 453]                 blk.30.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 433/ 453]               blk.30.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 434/ 453]              blk.30.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 435/ 453]            blk.30.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 436/ 453]                   blk.30.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 437/ 453]                 blk.30.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 438/ 453]                   blk.30.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 439/ 453]                 blk.30.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "[ 440/ 453]                blk.31.attn_norm.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 441/ 453]              blk.31.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 442/ 453]                   blk.31.ffn_up.bias - [10240,     1,     1,     1], type =    f32, size =    0.039 MB\n",
            "[ 443/ 453]                 blk.31.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, quantizing to q5_K .. size =    50.00 MiB ->    17.19 MiB\n",
            "[ 444/ 453]                 blk.31.ffn_down.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 445/ 453]               blk.31.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, quantizing to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 446/ 453]              blk.31.attn_output.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 447/ 453]            blk.31.attn_output.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 448/ 453]                   blk.31.attn_k.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 449/ 453]                 blk.31.attn_k.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 450/ 453]                   blk.31.attn_q.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 451/ 453]                 blk.31.attn_q.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q5_K .. size =    12.50 MiB ->     4.30 MiB\n",
            "[ 452/ 453]                   blk.31.attn_v.bias - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 453/ 453]                 blk.31.attn_v.weight - [ 2560,  2560,     1,     1], type =    f16, quantizing to q6_K .. size =    12.50 MiB ->     5.13 MiB\n",
            "llama_model_quantize_internal: model size  =  5303.65 MB\n",
            "llama_model_quantize_internal: quant size  =  1908.54 MB\n",
            "\n",
            "main: quantize time = 238446.12 ms\n",
            "main:    total time = 238446.12 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub\n",
        "\n",
        "from huggingface_hub import HfApi\n",
        "api = HfApi()\n",
        "\n",
        "model_id = \"praveeny/phi2-webglm-gguf\"\n",
        "api.create_repo(model_id, exist_ok=True, repo_type=\"model\")\n",
        "api.upload_file(\n",
        "    path_or_fileobj=\"phi2/phi2-v2-Q5_K_M.gguf\",\n",
        "    path_in_repo=\"phi2-v2-Q5_K_M.gguf\",\n",
        "    repo_id=model_id,\n",
        ")"
      ],
      "metadata": {
        "id": "fhSPYccab5-x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341,
          "referenced_widgets": [
            "673bce3c89f441f4ac408a74b4dcb676",
            "a99711209b8345fa9aa966d7f08bb6a5",
            "73a030fe03664ca1a8766d60f309cc07",
            "c078701328074d29b57358338147734b",
            "d6286a18c51148b0999669afb1b5ddab",
            "bc6758ebd9a043f5ae9b31bf79af03b6",
            "30218c5f80e44bb6b0bf4b12b928f2ab",
            "c3b226e05870413b9fa09292a232a3e6",
            "aaf26cc0852544d9a1027dc25675d977",
            "f12b2aac4307439c97bc65cd8741fa04",
            "f13ce0f32e8946c58ba9f12fc2e04494"
          ]
        },
        "outputId": "de18cbfa-b1e5-486f-88e6-c7b15153b2ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.2.2)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "phi2-v2-Q5_K_M.gguf:   0%|          | 0.00/2.00G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "673bce3c89f441f4ac408a74b4dcb676"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/praveeny/phi2-webglm-gguf/commit/897b106fc7b4c287aaf66b14e93e1f8bac5e9f29', commit_message='Upload phi2-v2-Q5_K_M.gguf with huggingface_hub', commit_description='', oid='897b106fc7b4c287aaf66b14e93e1f8bac5e9f29', pr_url=None, pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running Inference with LangChain, Llamacpp and GGUF\n",
        "\n",
        "At this point, I would recommend to disconnect and delete the runtime. The code below can be run separately and we will redownload the GGUF file from hugging face hub, then work with the local copy.\n",
        "\n",
        "I am also running this on a CPU instance, instead of GPU."
      ],
      "metadata": {
        "id": "zuzpm19uKB4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub\n",
        "!pip install langchain\n",
        "!pip install llama-cpp-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_1GboP-3-4Q",
        "outputId": "58da7e0c-54e6-45b9-b2da-c6f01f2a5f0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.2.2)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.1.9-py3-none-any.whl (816 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.0/817.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.27)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.21 (from langchain)\n",
            "  Downloading langchain_community-0.0.24-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.26 (from langchain)\n",
            "  Downloading langchain_core-0.1.26-py3-none-any.whl (246 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.4/246.4 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.2.0,>=0.1.0 (from langchain)\n",
            "  Downloading langsmith-0.1.8-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.26->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.26->langchain) (23.2)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.26->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.26->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: orjson, mypy-extensions, marshmallow, jsonpointer, typing-inspect, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-community, langchain\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.9 langchain-community-0.0.24 langchain-core-0.1.26 langsmith-0.1.8 marshmallow-3.20.2 mypy-extensions-1.0.0 orjson-3.9.15 typing-inspect-0.9.0\n",
            "Collecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.2.51.tar.gz (36.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.7/36.7 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (4.9.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.25.2)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\n",
            "Building wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.51-cp310-cp310-manylinux_2_35_x86_64.whl size=2669276 sha256=26c00e09a0adcca0a034c21fd47e5f8053124dea56554fd329315c9d485a442d\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/73/fc/63f2d69fbeab876766b03423ee6e00cd9429adec8dc24f13ee\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: diskcache, llama-cpp-python\n",
            "Successfully installed diskcache-5.6.3 llama-cpp-python-0.2.51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "model_id=\"praveeny/phi2-webglm-gguf\"\n",
        "#Download the repository to local_dir\n",
        "snapshot_download(repo_id=model_id, local_dir=\"phi2-gguf\",\n",
        "                  local_dir_use_symlinks=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132,
          "referenced_widgets": [
            "5d9976cf8cda4291a47bd407fb5a40c4",
            "00df33f0a69445708c1a8d55ea0991a3",
            "a9abb29ab19d4d3bb495ecd40c0b062d",
            "6bc6f650887742bd8db4f8fc9a46b872",
            "61fa7425c0e041fe83b2c896722006f7",
            "791b39ea4905475192d714acf11ab0ca",
            "88fb4b01a1b6415ea154a0324b67aa9c",
            "8c40456e36a94d77b3e6d801c4769b6d",
            "51ec619b54754d8b98661a29225caa16",
            "8548ea840444436eb9bba428945ba8a8",
            "5fad5e6adf834df48d1f04a07f8640fa",
            "23d9ac6a25ce49dcb4ac2402d23e9aca",
            "f392117f7e1a4976a5931fda7c44b5e2",
            "ae7498263bdc426cabcfaac07149b499",
            "9af82a387584471699c1ecf8de0f6bf0",
            "5bf477cc42154b5bac268323a70ad800",
            "c59150e2bc16406186dea32750b0302c",
            "687b7e049c7947a29d7109930c53829a",
            "6ff16270b95b43e283d6a3ad9843d923",
            "a8c10868a6544d7e867458442a60213e",
            "287bd3659e5e442daddf90c32aca3c5f",
            "2ba25a235ca24346b46316aff9448e2e",
            "f4504f84b82a466eb8420d4d030a6e0d",
            "94bed744ad2a4ce4949199d926d0061d",
            "938592446589411c86d50e1b3c7f4605",
            "b43ab566caf34bf8affbb6bf991e3162",
            "a61bb0b00eeb4fc2a364194f3c7449e6",
            "1bc8a781a0d947cbab68c9e84863e99a",
            "2a5a0e1172b144418919e6b03bdbb405",
            "a673ed55d6c24069b54adae3c90db7ff",
            "fbff580fc03c41849c33a244e111c405",
            "bcdd1879078942aa94a7428fe3e24109",
            "2e7a04dc3a5441faae34f7a52971190e"
          ]
        },
        "id": "cb_wcmZi4Z0I",
        "outputId": "132c2dc8-d171-4ea7-9010-62916740aa4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d9976cf8cda4291a47bd407fb5a40c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              ".gitattributes:   0%|          | 0.00/1.57k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "23d9ac6a25ce49dcb4ac2402d23e9aca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "phi2-v2-Q5_K_M.gguf:   0%|          | 0.00/2.00G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f4504f84b82a466eb8420d4d030a6e0d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/phi2-gguf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up LangChain and prompt"
      ],
      "metadata": {
        "id": "QGg3gGth4z4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.callbacks.manager import CallbackManager\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_community.llms import LlamaCpp\n",
        "\n",
        "# Callbacks support token-wise streaming\n",
        "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])"
      ],
      "metadata": {
        "id": "5jZpmzVL4-eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running inference with Llamacpp"
      ],
      "metadata": {
        "id": "6maDyHiX5Frv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure the model path is correct for your system!\n",
        "llm = LlamaCpp(\n",
        "    model_path=\"phi2-gguf/phi2-v2-Q5_K_M.gguf\",\n",
        "    temperature=0.75,\n",
        "    max_tokens=2000,\n",
        "    top_p=1,\n",
        "    callback_manager=callback_manager,\n",
        "    verbose=True,  # Verbose is required to pass to the callback manager\n",
        ")\n",
        "\n",
        "\n",
        "prompt = \"\"\"###System:\n",
        "Read the references provided and answer the corresponding question.\n",
        "###References:\n",
        "[1] For most people, the act of reading is a reward in itself. However, studies show that reading books also has benefits that range from a longer life to career success. If you’re looking for reasons to pick up a book, read on for seven science-backed reasons why reading is good for your health, relationships and happiness.\n",
        "[2] As per a study, one of the prime benefits of reading books is slowing down mental disorders such as Alzheimer’s and Dementia  It happens since reading stimulates the brain and keeps it active, which allows it to retain its power and capacity.\n",
        "[3] Another one of the benefits of reading books is that they can improve our ability to empathize with others. And empathy has many benefits – it can reduce stress, improve our relationships, and inform our moral compasses.\n",
        "[4] Here are 10 benefits of reading that illustrate the importance of reading books. When you read every day you:\n",
        "[5] Why is reading good for you? Reading is good for you because it improves your focus, memory, empathy, and communication skills. It can reduce stress, improve your mental health, and help you live longer. Reading also allows you to learn new things to help you succeed in your work and relationships.\n",
        "###Question:\n",
        "Why is reading books widely considered to be beneficial?\n",
        "###Answer:\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "llm.invoke(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RiyK4yFi5La3",
        "outputId": "9ee14d48-3904-4fde-c6f4-b3b1d6e56667"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 20 key-value pairs and 453 tensors from phi2-gguf/phi2-v2-Q5_K_M.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = phi2\n",
            "llama_model_loader: - kv   1:                               general.name str              = Phi2\n",
            "llama_model_loader: - kv   2:                        phi2.context_length u32              = 2048\n",
            "llama_model_loader: - kv   3:                      phi2.embedding_length u32              = 2560\n",
            "llama_model_loader: - kv   4:                   phi2.feed_forward_length u32              = 10240\n",
            "llama_model_loader: - kv   5:                           phi2.block_count u32              = 32\n",
            "llama_model_loader: - kv   6:                  phi2.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   7:               phi2.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv   8:          phi2.attention.layer_norm_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv   9:                  phi2.rope.dimension_count u32              = 32\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 17\n",
            "llama_model_loader: - kv  11:               tokenizer.ggml.add_bos_token bool             = false\n",
            "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,51200]   = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,51200]   = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  15:                      tokenizer.ggml.merges arr[str,50000]   = [\"Ġ t\", \"Ġ a\", \"h e\", \"i n\", \"r e\",...\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 50256\n",
            "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 50256\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 50256\n",
            "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:  259 tensors\n",
            "llama_model_loader: - type q5_K:  161 tensors\n",
            "llama_model_loader: - type q6_K:   33 tensors\n",
            "llm_load_vocab: mismatch in special tokens definition ( 910/51200 vs 944/51200 ).\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = phi2\n",
            "llm_load_print_meta: vocab type       = BPE\n",
            "llm_load_print_meta: n_vocab          = 51200\n",
            "llm_load_print_meta: n_merges         = 50000\n",
            "llm_load_print_meta: n_ctx_train      = 2048\n",
            "llm_load_print_meta: n_embd           = 2560\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 32\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 32\n",
            "llm_load_print_meta: n_embd_head_k    = 80\n",
            "llm_load_print_meta: n_embd_head_v    = 80\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: n_embd_k_gqa     = 2560\n",
            "llm_load_print_meta: n_embd_v_gqa     = 2560\n",
            "llm_load_print_meta: f_norm_eps       = 1.0e-05\n",
            "llm_load_print_meta: f_norm_rms_eps   = 0.0e+00\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 10240\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 2\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 2048\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: model type       = 3B\n",
            "llm_load_print_meta: model ftype      = Q5_K - Medium\n",
            "llm_load_print_meta: model params     = 2.78 B\n",
            "llm_load_print_meta: model size       = 1.86 GiB (5.76 BPW) \n",
            "llm_load_print_meta: general.name     = Phi2\n",
            "llm_load_print_meta: BOS token        = 50256 '<|endoftext|>'\n",
            "llm_load_print_meta: EOS token        = 50256 '<|endoftext|>'\n",
            "llm_load_print_meta: UNK token        = 50256 '<|endoftext|>'\n",
            "llm_load_print_meta: LF token         = 128 'Ä'\n",
            "llm_load_tensors: ggml ctx size =    0.17 MiB\n",
            "llm_load_tensors:        CPU buffer size =  1908.54 MiB\n",
            ".............................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 512\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:        CPU KV buffer size =   160.00 MiB\n",
            "llama_new_context_with_model: KV self size  =  160.00 MiB, K (f16):   80.00 MiB, V (f16):   80.00 MiB\n",
            "llama_new_context_with_model:        CPU input buffer size   =     0.10 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =     1.64 MiB\n",
            "llama_new_context_with_model: graph splits (measure): 1\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n",
            "Model metadata: {'tokenizer.ggml.unknown_token_id': '50256', 'tokenizer.ggml.eos_token_id': '50256', 'tokenizer.ggml.bos_token_id': '50256', 'general.architecture': 'phi2', 'general.name': 'Phi2', 'phi2.context_length': '2048', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'tokenizer.ggml.add_bos_token': 'false', 'phi2.embedding_length': '2560', 'phi2.attention.head_count': '32', 'phi2.attention.head_count_kv': '32', 'phi2.feed_forward_length': '10240', 'phi2.attention.layer_norm_epsilon': '0.000010', 'phi2.block_count': '32', 'phi2.rope.dimension_count': '32', 'general.file_type': '17'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading books is widely considered to be beneficial because it can improve focus, memory, empathy, and communication skills[5], reduce stress, improve mental health, and help you live longer[5], and allow you to learn new things to help you succeed in your work and relationships[5]. It can also slow down mental disorders such as Alzheimer’s and Dementia by stimulating the brain and keeping it active[2], and improve our ability to empathize with others which can reduce stress, improve our relationships, and inform our moral compasses[3]. Additionally, it can improve our ability to comprehend and retain information, which can help us succeed academically[4]. Finally, it can be rewarding in itself as it can be an enjoyable activity[1]."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =    2947.97 ms\n",
            "llama_print_timings:      sample time =     161.15 ms /   155 runs   (    1.04 ms per token,   961.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =   80168.12 ms /   302 tokens (  265.46 ms per token,     3.77 tokens per second)\n",
            "llama_print_timings:        eval time =   56772.21 ms /   154 runs   (  368.65 ms per token,     2.71 tokens per second)\n",
            "llama_print_timings:       total time =  138518.75 ms /   456 tokens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Reading books is widely considered to be beneficial because it can improve focus, memory, empathy, and communication skills[5], reduce stress, improve mental health, and help you live longer[5], and allow you to learn new things to help you succeed in your work and relationships[5]. It can also slow down mental disorders such as Alzheimer’s and Dementia by stimulating the brain and keeping it active[2], and improve our ability to empathize with others which can reduce stress, improve our relationships, and inform our moral compasses[3]. Additionally, it can improve our ability to comprehend and retain information, which can help us succeed academically[4]. Finally, it can be rewarding in itself as it can be an enjoyable activity[1].'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}